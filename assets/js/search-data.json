{
  
    
        "post0": {
            "title": "",
            "content": "%load_ext autoreload %autoreload 2 %matplotlib inline . import pandas as pd import numpy as np import load_covid_data from IPython.display import display, Markdown import matplotlib.pyplot as plt import matplotlib import seaborn as sns import arviz as az import pymc3 as pm import altair as alt sns.set_context(&#39;talk&#39;) plt.style.use(&#39;seaborn-whitegrid&#39;) debug=False . ModuleNotFoundError Traceback (most recent call last) &lt;ipython-input-2-41c4e007cbd0&gt; in &lt;module&gt; 1 import pandas as pd 2 import numpy as np -&gt; 3 import load_covid_data 4 from IPython.display import display, Markdown 5 import matplotlib.pyplot as plt ModuleNotFoundError: No module named &#39;load_covid_data&#39; . df = load_covid_data.load_data(drop_states=True, filter_n_days_100=2) . df = df.loc[lambda x: x.country != &#39;Chinal (total)&#39;] countries = df.country.unique() n_countries = len(countries) df = df.loc[lambda x: (x.days_since_100 &gt;= 0)] . df.index.max().strftime(&#39;%B %d, %Y&#39;) . &#39;March 28, 2020&#39; . annotate_kwargs = dict( s=&#39;Dateset by COVID Data Repository by Johns Hopkins CSSE ({}) nBy Guilherme Diaz-Berrio, based on the work by Thomas Wiecki&#39;.format(df.index.max().strftime(&#39;%B %d, %Y&#39;)), xy=(0.05, 0.01), xycoords=&#39;figure fraction&#39;, fontsize=10) . annotate_kwargs . {&#39;s&#39;: &#39;Dateset by COVID Data Repository by Johns Hopkins CSSE (March 28, 2020) nBy Guilherme Diaz-Berrio, based on the work by Thomas Wiecki&#39;, &#39;xy&#39;: (0.05, 0.01), &#39;xycoords&#39;: &#39;figure fraction&#39;, &#39;fontsize&#39;: 10} . &#39;, &#39;.join(countries.tolist()) . &#39;Albania, Algeria, Andorra, Argentina, Armenia, Austria, Azerbaijan, Bahrain, Belgium, Bosnia and Herzegovina, Brazil, Brunei, Bulgaria, Burkina Faso, Chile, Hong Kong, Colombia, Costa Rica, Croatia, Diamond Princess, Cyprus, Czechia, Denmark, Dominican Republic, Ecuador, Egypt, Estonia, Finland, France, Germany, Ghana, Greece, Hungary, Iceland, India, Indonesia, Iran, Iraq, Ireland, Israel, Italy, Japan, Jordan, Kazakhstan, Korea, South, Kuwait, Latvia, Lebanon, Lithuania, Luxembourg, Malaysia, Malta, Mexico, Moldova, Morocco, Netherlands, New Zealand, North Macedonia, Norway, Oman, Pakistan, Panama, Peru, Philippines, Poland, Portugal, Qatar, Romania, Russia, San Marino, Saudi Arabia, Senegal, Serbia, Singapore, Slovakia, Slovenia, South Africa, Spain, Sri Lanka, Sweden, Switzerland, Taiwan*, Thailand, Tunisia, Turkey, Ukraine, United Arab Emirates, United Kingdom, Uruguay, US, Venezuela, Vietnam, Australia (total), Canada (total), China (total), Denmark (total), France (total), United Kingdom (total)&#39; . with pm.Model() as exp_model: # Intercept a_grp = pm.Normal(&#39;a_grp&#39;, 100, 50) # Group Mean a_grp_sigma = pm.HalfNormal(&#39;a_grp_sigma&#39;, 50) # Group Variance a_ind = pm.Normal(&#39;a_ind&#39;, mu=a_grp, sigma=a_grp_sigma, shape=n_countries) # Individual Intercepts # Slope b_grp = pm.Normal(&#39;b_grp&#39;, 1.33, 0.5) # Group Mean b_grp_sigma = pm.HalfNormal(&#39;b_grp_sigma&#39;, .5) # Group Variance b_ind = pm.Normal(&#39;b_ind&#39;, mu=b_grp, sigma=b_grp_sigma, shape=n_countries) # Individual slopes # Error sigma = pm.HalfNormal(&#39;sigma&#39;, 500., shape=n_countries) # Create likelihood for each country for i, country in enumerate(countries): df_country = df.loc[lambda x: (x.country == country)] # By using pm.Data we can change these values after sampling. # This allows us to extend x into the future so we can get # forecasts by sampling from the posterior predictive x = pm.Data(country + &quot;x_data&quot;, df_country.days_since_100.values) confirmed = pm.Data(country + &quot;y_data&quot;, df_country.confirmed.astype(&#39;float64&#39;).values) # Likelihood pm.NegativeBinomial( country, (a_ind[i] * b_ind[i] ** x), # Exponential Regression sigma[i], observed=confirmed) . with exp_model: trace = pm.sample(tune=1500, chains=2, cores=1, target_accept=.9) # update data so we get predictions into the future for country in countries: df_country = df.loc[lambda x: (x.country == country)] x_data = np.arange(0, 45) y_data = np.array([np.nan] * len(x_data)) pm.set_data({country + &quot;x_data&quot;: x_data}) pm.set_data({country + &quot;y_data&quot;: y_data}) post_pred = pm.sample_posterior_predictive(trace, samples=80) . Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... Sequential sampling (2 chains in 1 job) NUTS: [sigma, b_ind, b_grp_sigma, b_grp, a_ind, a_grp_sigma, a_grp] Sampling chain 0, 0 divergences: 100%|█████████████████████████████████████████████| 2000/2000 [33:09&lt;00:00, 1.01it/s] Sampling chain 1, 0 divergences: 100%|█████████████████████████████████████████████| 2000/2000 [24:25&lt;00:00, 1.36it/s] The acceptance probability does not match the target. It is 0.9766857378384846, but should be close to 0.9. Try to increase the number of tuning steps. The acceptance probability does not match the target. It is 0.9714740509025667, but should be close to 0.9. Try to increase the number of tuning steps. C: Users gdb AppData Local Continuum anaconda3 lib site-packages pymc3 sampling.py:1247: UserWarning: samples parameter is smaller than nchains times ndraws, some draws and/or chains may not be represented in the returned posterior predictive sample &#34;samples parameter is smaller than nchains times ndraws, some draws &#34; 1%|█ | 1/80 [00:03&lt;04:48, 3.66s/it] . ValueError Traceback (most recent call last) ~ AppData Local Continuum anaconda3 lib site-packages pymc3 distributions distribution.py in _draw_value(param, point, givens, size) 800 try: --&gt; 801 return dist_tmp.random(point=point, size=size) 802 except (ValueError, TypeError): ~ AppData Local Continuum anaconda3 lib site-packages pymc3 distributions discrete.py in random(self, point, size) 665 g[g == 0] = np.finfo(float).eps # Just in case --&gt; 666 return np.asarray(stats.poisson.rvs(g)).reshape(g.shape) 667 ~ AppData Local Continuum anaconda3 lib site-packages scipy stats _distn_infrastructure.py in rvs(self, *args, **kwargs) 2968 kwargs[&#39;discrete&#39;] = True -&gt; 2969 return super(rv_discrete, self).rvs(*args, **kwargs) 2970 ~ AppData Local Continuum anaconda3 lib site-packages scipy stats _distn_infrastructure.py in rvs(self, *args, **kwds) 979 self._size = size --&gt; 980 vals = self._rvs(*args) 981 ~ AppData Local Continuum anaconda3 lib site-packages scipy stats _discrete_distns.py in _rvs(self, mu) 600 def _rvs(self, mu): --&gt; 601 return self._random_state.poisson(mu, self._size) 602 mtrand.pyx in numpy.random.mtrand.RandomState.poisson() _common.pyx in numpy.random._common.disc() _common.pyx in numpy.random._common.discrete_broadcast_d() _common.pyx in numpy.random._common.check_array_constraint() ValueError: lam value too large During handling of the above exception, another exception occurred: ValueError Traceback (most recent call last) &lt;ipython-input-144-977d2eb2c406&gt; in &lt;module&gt; 10 pm.set_data({country + &#34;y_data&#34;: y_data}) 11 &gt; 12 post_pred = pm.sample_posterior_predictive(trace, samples=80) ~ AppData Local Continuum anaconda3 lib site-packages pymc3 sampling.py in sample_posterior_predictive(trace, samples, model, vars, var_names, size, keep_size, random_seed, progressbar) 1279 param = trace[idx % len_trace] 1280 -&gt; 1281 values = draw_values(vars, point=param, size=size) 1282 for k, v in zip(vars, values): 1283 ppc_trace_t.insert(k.name, v, idx) ~ AppData Local Continuum anaconda3 lib site-packages pymc3 distributions distribution.py in draw_values(params, point, size) 618 point=point, 619 givens=temp_givens, --&gt; 620 size=size) 621 givens[next_.name] = (next_, value) 622 drawn[(next_, size)] = value ~ AppData Local Continuum anaconda3 lib site-packages pymc3 distributions distribution.py in _draw_value(param, point, givens, size) 808 with _DrawValuesContextBlocker(): 809 val = np.atleast_1d(dist_tmp.random(point=point, --&gt; 810 size=None)) 811 # Sometimes point may change the size of val but not the 812 # distribution&#39;s shape ~ AppData Local Continuum anaconda3 lib site-packages pymc3 distributions discrete.py in random(self, point, size) 664 size=size) 665 g[g == 0] = np.finfo(float).eps # Just in case --&gt; 666 return np.asarray(stats.poisson.rvs(g)).reshape(g.shape) 667 668 def logp(self, value): ~ AppData Local Continuum anaconda3 lib site-packages scipy stats _distn_infrastructure.py in rvs(self, *args, **kwargs) 2967 &#34;&#34;&#34; 2968 kwargs[&#39;discrete&#39;] = True -&gt; 2969 return super(rv_discrete, self).rvs(*args, **kwargs) 2970 2971 def pmf(self, k, *args, **kwds): ~ AppData Local Continuum anaconda3 lib site-packages scipy stats _distn_infrastructure.py in rvs(self, *args, **kwds) 978 # by _rvs(). 979 self._size = size --&gt; 980 vals = self._rvs(*args) 981 982 vals = vals * scale + loc ~ AppData Local Continuum anaconda3 lib site-packages scipy stats _discrete_distns.py in _rvs(self, mu) 599 600 def _rvs(self, mu): --&gt; 601 return self._random_state.poisson(mu, self._size) 602 603 def _logpmf(self, k, mu): mtrand.pyx in numpy.random.mtrand.RandomState.poisson() _common.pyx in numpy.random._common.disc() _common.pyx in numpy.random._common.discrete_broadcast_d() _common.pyx in numpy.random._common.check_array_constraint() ValueError: lam value too large . # flatten predictions &amp; target for each country into a pandas DataFrame predictions_dfs_list = [] for country in post_pred: arr = post_pred[country] preds = arr.flatten().tolist() # get predictions in flattened array pred_idx = np.indices(arr.shape)[0].flatten().tolist() # predictions for the model (grey lines) days_since = np.indices(arr.shape)[1].flatten().tolist() # days since 100 cases pred_df = pd.DataFrame( { &#39;country&#39;: country, &#39;predictions&#39;: preds, &#39;pred_idx&#39;: pred_idx, &#39;days_since_100&#39;: days_since } ) predictions_dfs_list.append(pred_df) predictionsDF = pd.concat(predictions_dfs_list) # Compute the maximum value to plot on the y-axis as 15x the last confirmed case ylims = pd.DataFrame(df.groupby(&#39;country&#39;).last().confirmed * 15).reset_index() ylims.columns = [&#39;country&#39;, &#39;ylim&#39;] # filter predictions that exceed ylims predictionsDF_filtered = (predictionsDF.merge(ylims, on=&#39;country&#39;, how=&#39;left&#39;).loc[lambda x: x.predictions &lt;= x.ylim]) # compute 33% daily growth rate for reference first_case_count = df.groupby(&#39;country&#39;).first().confirmed.reset_index() date_anchor = predictionsDF_filtered[[&#39;country&#39;, &#39;days_since_100&#39;]].drop_duplicates() max_pred = predictionsDF_filtered.groupby(&#39;country&#39;).max()[[&#39;predictions&#39;]].reset_index() benchmark = (date_anchor .merge(first_case_count, on=&#39;country&#39;, how=&#39;left&#39;) .merge(max_pred, on=&#39;country&#39;, how=&#39;left&#39;)) benchmark[&#39;benchmark&#39;] = benchmark.apply(lambda x: x.confirmed * (1.3 ** (x.days_since_100)), axis=1) benchmarkDF_filtered = benchmark.loc[lambda x: x.benchmark &lt;= x.predictions] # compute last known confirmed case lastpointDF = df.groupby(&#39;country&#39;).last().reset_index() # DF of chart titles. Hack for Altiar to switch values titleDF = lastpointDF[[&#39;country&#39;]] titleDF[&#39;title&#39;] = titleDF.apply(lambda x: x.country + &#39;: Actual vs Predicted Growth&#39;, axis=1) . C: Users gdb AppData Local Continuum anaconda3 lib site-packages ipykernel_launcher.py:43: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy . european_countries = [&#39;Italy&#39;, &#39;Spain&#39;, &#39;United Kingdom (total)&#39;, &#39;France (total)&#39;, &#39;Portugal&#39;] asian_countries = [&#39;Korea, South&#39;, &#39;Japan&#39;, &#39;China (total)&#39;, &#39;Singapore&#39;] country_groups = [european_countries, asian_countries] line_styles = [&#39;-&#39;, &#39;:&#39;, &#39;--&#39;, &#39;-.&#39;] fig, axs = plt.subplots(nrows=len(country_groups), figsize=(8, 16), sharex=False) for ax, country_group in zip(axs, country_groups): for i, country in enumerate(countries): if country in country_group: sns.distplot((trace[&#39;b_ind&#39;][:, i] * 100) - 100, ax=ax, label=country, hist=False) display(f&quot;Country Mean Growth - {country}:{np.mean((trace[&#39;b_ind&#39;][:, i] * 100) - 100)}&quot;) ax.axvline(33, ls=&#39;--&#39;, color=&#39;k&#39;, label=&#39;33% daily growth&#39;) ax.legend() ax.set_xlabel(&#39;Daily Growth in %&#39;) plt.suptitle(&#39;Posterior of daily growth&#39;) . &#39;Country Mean Growth - Italy:21.03937347912671&#39; . &#39;Country Mean Growth - Portugal:28.552267573492166&#39; . &#39;Country Mean Growth - Spain:29.541861982198792&#39; . &#39;Country Mean Growth - France (total):16.680928284662446&#39; . &#39;Country Mean Growth - United Kingdom (total):24.526988778914767&#39; . &#39;Country Mean Growth - Japan:7.354671198062449&#39; . &#39;Country Mean Growth - Korea, South:13.963748866984483&#39; . &#39;Country Mean Growth - Singapore:8.305400197697537&#39; . &#39;Country Mean Growth - China (total):16.693933862488556&#39; . Text(0.5, 0.98, &#39;Posterior of daily growth&#39;) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; # Charts Linear Scale sub_countries = [&#39;Italy&#39;, &#39;Spain&#39;, &#39;United Kingdom (total)&#39;, &#39;France (total)&#39;, &#39;Portugal&#39;, &#39;Korea, South&#39;] fig, axs = plt.subplots(nrows=(len(sub_countries) // 3), ncols=3, figsize=(30, 30), sharex=True) for ax, country in zip(axs.flatten(), sub_countries): df_country = df.loc[lambda x: x.country == country] ax.plot(df_country.days_since_100, df_country.confirmed, color=&#39;r&#39;) ax.plot(np.arange(0, post_pred[country].shape[1]), post_pred[country].T, alpha=.05, color=&#39;.5&#39;) ax.plot(df_country.days_since_100, df_country.confirmed, color=&#39;r&#39;) ax.set_ylim(0, df_country.confirmed.iloc[-1] * 15) ax.set_title(country) axs[0, 0].legend([&#39;data&#39;, &#39;model prediction&#39;]) [ax.set(xlabel=&#39;Days since 100 cases&#39;) for ax in axs[-1, :]] [ax.set(ylabel=&#39;Confirmed cases&#39;) for ax in axs[:, 0]] plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; # Charts Log Scale sub_countries = [&#39;Italy&#39;, &#39;Spain&#39;, &#39;United Kingdom (total)&#39;, &#39;France (total)&#39;, &#39;Portugal&#39;, &#39;Korea, South&#39;] fig, axs = plt.subplots(nrows=(len(sub_countries) // 3), ncols=3, figsize=(30, 30), sharex=True) for ax, country in zip(axs.flatten(), sub_countries): df_country = df.loc[lambda x: x.country == country] ax.plot(df_country.days_since_100, df_country.confirmed, color=&#39;r&#39;) ax.plot(np.arange(0, post_pred[country].shape[1]), post_pred[country].T, alpha=.05, color=&#39;.5&#39;) ax.plot(df_country.days_since_100, df_country.confirmed, color=&#39;r&#39;) ax.set_yscale(&#39;log&#39;) ax.get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter()) ax.set_title(country) axs[0, 0].legend([&#39;data&#39;, &#39;model prediction&#39;]) [ax.set(xlabel=&#39;Days since 100 cases&#39;) for ax in axs[-1, :]] [ax.set(ylabel=&#39;Confirmed cases&#39;) for ax in axs[:, 0]] plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; az.plot_trace(trace, compact=True) . array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000001741C4FCA20&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000017411F7A8D0&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000173F3B24710&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000017416FE5DA0&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000017410E8BF98&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000173C81C4710&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000017416F05898&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000174190CD208&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000001742A7D7E10&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000017402CD47F0&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000173A8A6ADA0&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000173BB522828&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000173D83D6C88&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000174251B4978&gt;]], dtype=object) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt;",
            "url": "https://gdberrio.github.io/blog/2020/06/26/2020-03-31-covid-19_expo_model.html",
            "relUrl": "/2020/06/26/2020-03-31-covid-19_expo_model.html",
            "date": " • Jun 26, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Hierarchical Models",
            "content": "Hierarchical Models . Books . Forecasting: Principles and Practice - Hierarchical or Grouped Time Series . Forecasting: Principles and Practice - Chapter 10 Forecasting hierarchical or grouped time series . Blog Posts . Bayesian Methods for Multilevel Modelling . A Primer on Bayesian Methods for Multilevel Modeling . Hierarchical Linear Regression in PyMC3 . The best of both worlds: Hierarchical Linear Regression in PyMC3 . Introduction . Hierarchical modeling is especially advantageous when in the presence of multi-level data, making the most of all available information by it’s “shrinkage-effect”. Software like HDDM allows hierarchical Bayesian estimation of a widely used decision making model, but here we will use a classical example of hierarchical linear regression to predict radon levels in houses. . Gelman et al.’s (2007) radon dataset is the canonical example for Bayesian Hierarchical Modelling. In the dataset the amount of radiation has been measured amongst different households in all counties of several US States. Radon gas is known as the highest cause of lung cancer in non-smokers. It is believed to enter the house through the basement. Additionally its concentration differs regionally due to differences in soil type. . The exercise is to attempt to predict radon levels in different counties and where in the house it was measured. . Data Source: radon.csv Columns: county, log_radon, floor where floor = 0 is the basement, floor = 1 is the 1st floor, and so forth. . Single regression (pooled model) . A common way of solving this would be to pool all the data and estimate one regression to assess the influence of measurement across counties. The model would follow the following specification: . radoni,c=α+β∗floori,c+ϵradon_{i,c} = alpha + beta * floor_{i,c} + epsilonradoni,c​=α+β∗floori,c​+ϵ . where $i$ corresponds to the measurement, $c$ corresponds to the county and floor corresponds to which floor the measurement was made. We then estimate a single intercept and a single slope for all measurements over all counties. We are assuming that all the counties are exactly the same. . Separate regressions (unpooled model) . Imagine however we were interested, for instance, in seeing the differences in relationship (slope) or base-rates of radon (intercept) across counties. We could generate $n$ regressions, where $n$ is the number of counties. Such model would follow the following specification: . radoni,c=αc+βc∗floori,c+ϵcradon_{i,c} = alpha_c + beta_c * floor_{i,c} + epsilon_cradoni,c​=αc​+βc​∗floori,c​+ϵc​ . Now, for every county $c$, we are estimating $ alpha_c$ and $ beta_c$, up to $n$ total counties. In this version, the upooled version, we assume the extreme opposite of the former model. Instead of assuming all counties are exactly the same, we are assuming they share no similarities between them. . Hierarchical Regression . There is a middle ground between a fully pooled model and an unpooled model. It’s a Hierarchical Model. Specifically, while we may assume that while $ alpha$s and $ beta$s are different for each county, they all come from a common group distribution: . αc∼N(μα,σα2)βc∼N(μβ,σβ2) alpha_c sim mathcal{N}( mu_ alpha, sigma^2_ alpha) beta_c sim mathcal{N}( mu_ beta, sigma^2_ beta)αc​∼N(μα​,σα2​)βc​∼N(μβ​,σβ2​) . Here the assumption is that the intercepts $ alpha$ and slopes $ beta$ all come from a normal distribution centered around their respective group mean $ mu$ with a certain standard deviation $ sigma^2$, values (posteriors) which we also estimate. It is for this reason that such a model is named Multilevel or Hierarchical. . Using Probabilistic Programming, with a framework like pyMC3, . Advanced Hierarchical Linear Regression in PyMC3 . Why hierarchical models are awesome, tricky, and Bayesian . HDDM Demo . HDDM Demo . Tools . htsprophet HDDM . Extra Notes . The Inference Button: Bayesian GLMs made easy with PyMC3 This world is far from Normal(ly distributed): Bayesian Robust Regression in PyMC3 .",
            "url": "https://gdberrio.github.io/blog/markdown/2020/06/26/Hierarchical-Forecasting.html",
            "relUrl": "/markdown/2020/06/26/Hierarchical-Forecasting.html",
            "date": " • Jun 26, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://gdberrio.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://gdberrio.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://gdberrio.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}